{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 76/249 [00:01<00:03, 55.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeeping file 1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 203/249 [00:04<00:00, 48.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeeping file 3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 240/249 [00:04<00:00, 46.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeeping file 4659\n",
      "skeeping file 4699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:05<00:00, 49.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120311, 8)\n",
      "(120311,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#reading all the files\n",
    "\n",
    "#reading the first file\n",
    "df = pd.read_csv('../src/outputs/run_history_19.csv', sep=';', index_col=0)\n",
    "df_emb = pd.read_csv('../src/outputs/run_history_emb_idx_19.csv', sep=';', index_col=0)\n",
    "np_emb_state = np.load('../src/outputs/emb_states_19.npy', allow_pickle=True)\n",
    "np_emb_next_state = np.load('../src/outputs/next_states_19.npy', allow_pickle=True)\n",
    "\n",
    "skeeped_files = []\n",
    "#adding all the others\n",
    "list1 = list(range(39, 5000, 20))\n",
    "for i in tqdm.tqdm(list1):\n",
    "    s1 = '../src/outputs/run_history_' + str(i) + '.csv'\n",
    "    df_ = pd.read_csv(s1, sep=';', index_col=0)\n",
    "    s2 = '../src/outputs/emb_states_' + str(i) + '.npy'\n",
    "    np_emb_state_ = np.load(s2, allow_pickle=True)\n",
    "    if np_emb_state_.shape[0] != df_.shape[0]:\n",
    "        print ('skeeping file %d' %i)\n",
    "        skeeped_files.append(s1)\n",
    "        skeeped_files.append(s2)\n",
    "    else:\n",
    "        df = pd.concat([df,df_], axis=0)\n",
    "        np_emb_state = np.concatenate((np_emb_state, np_emb_state_))\n",
    "        \n",
    "print(df.shape)\n",
    "print(np_emb_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_emb_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_emb_state_float = [x.astype(np.float64) for x in np_emb_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensor_emb = torch.Tensor(np.array(np_emb_state_float)) \n",
    "dataset = TensorDataset(tensor_emb) \n",
    "loader = DataLoader(dataset, batch_size = 64,\n",
    "   shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 768])\n"
     ]
    }
   ],
   "source": [
    "for emb in loader:\n",
    "    print(emb[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoenc(torch.nn.Module):\n",
    "   def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      self.encoder = torch.nn.Sequential(\n",
    "         torch.nn.Linear(768, 512),\n",
    "         torch.nn.ReLU(),\n",
    "         torch.nn.Linear(512, 256),\n",
    "         torch.nn.ReLU(),\n",
    "         torch.nn.Linear(256, 128),\n",
    "         torch.nn.ReLU(),\n",
    "         torch.nn.Linear(128, 64),\n",
    "      )\n",
    "\n",
    "      self.decoder = torch.nn.Sequential(\n",
    "         torch.nn.Linear(64, 128),\n",
    "         torch.nn.ReLU(),\n",
    "         torch.nn.Linear(128, 256),\n",
    "         torch.nn.ReLU(),\n",
    "         torch.nn.Linear(256, 512),\n",
    "         torch.nn.ReLU(),\n",
    "         torch.nn.Linear(512, 768)\n",
    "      )\n",
    "   def forward(self, x):\n",
    "      encoded = self.encoder(x)\n",
    "      decoded = self.decoder(encoded)\n",
    "      return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoenc()\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-1, weight_decay = 1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1821, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1842, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1829, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1849, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1819, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1826, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1800, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:11<01:40, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1829, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1866, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1797, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1848, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1847, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1847, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1828, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:20<01:21, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1849, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1843, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1828, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1846, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1842, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:30<01:09,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1826, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1864, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1842, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1803, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:39<00:56,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1849, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1807, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1829, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1826, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1855, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:47<00:45,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1848, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1852, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1851, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1812, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1802, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:55<00:35,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1841, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1854, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1860, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1851, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1805, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1868, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1857, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1865, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:04<00:26,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1821, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1858, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1892, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1833, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1821, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1810, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1876, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1843, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1823, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:13<00:17,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1860, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1841, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1800, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1856, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1865, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1818, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1826, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1803, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:22<00:08,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1830, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1838, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1870, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1842, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1811, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1858, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1795, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1842, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1851, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1828, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1861, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1812, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1852, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:30<00:00,  9.10s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mIterations\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m plt\u001b[39m.\u001b[39;49mplot(losses[\u001b[39m-\u001b[39;49m\u001b[39m100\u001b[39;49m:])\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/matplotlib/axes/_base.py:496\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    494\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mupdate_units(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/matplotlib/cbook/__init__.py:1656\u001b[0m, in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1656\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(y)\n\u001b[1;32m   1657\u001b[0m \u001b[39mexcept\u001b[39;00m (np\u001b[39m.\u001b[39mVisibleDeprecationWarning, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/matplotlib/cbook/__init__.py:1348\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[39m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[39m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[39m# Note this will strip unit information.\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m         \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m-> 1348\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[1;32m   1349\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[0;32m---> 65\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[1;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/causalscm/lib/python3.11/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApAAAAHUCAYAAACNlBi3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2dklEQVR4nO3deVzV1b7/8TeDiEGAaW4lRUPFpI7dyiwRh0Q9dcgJ5WaDldlgddWywUeZp0tmZJ3MzMwGM0kl0yCnIycGi/Doza527KYdURwgFccN6BFB4PdHP/aRmFzujXtveD0fDx7aWt+91vr2advb7+hhtVorBAAAAFwgT2cvAAAAAO6FAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjbhEgly9frqeeekoDBgxQmzZtFBQUpKVLlxqPU15erg8++EARERFq27atOnfurPHjx2vfvn2OXzQAAEAj5e3sBVyIV199Vbm5uWrVqpUsFotyc3MvapynnnpKCQkJ6t69ux577DEdOnRIX331lTIyMpSWlqbOnTs7eOUAAACNj1scgXz33Xe1fft27dmzRw899NBFjZGZmamEhARFRETo22+/VVxcnD788EMtXbpUJ0+e1HPPPefgVQMAADRObnEEcsCAAXaPkZCQIEmaNm2afHx8bO2DBw9WZGSkMjIylJubqw4dOtg9FwAAQGPmFkcgHSErK0t+fn669dZbq/VFRUVJkjZu3HiplwUAAOB2mkSAPH36tA4fPqyOHTvKy8urWn9oaKgkac+ePZd6aQAAAG6nSQTIwsJCSVJAQECN/ZXtldsBAACgdk0iQAIAAMBxmkSArO8IY31HKOHeiouLlZOTo+LiYmcvBYaonfuidu6N+qE+TSJA+vn5qW3bttq/f7/Kysqq9efk5EgSz4FsxGqqO9wDtXNf1M69UT/UpUkESEnq06ePTp8+rc2bN1frS09PlyRFRERc6mUBAAC4nUYXII8fP65du3bp+PHjVdofeOABSdLMmTNVUlJia09NTVVWVpYGDhyokJCQS7pWAAAAd+QWDxJPSEjQpk2bJEk7duyQJH322WfKysqSJPXu3Vv333+/JOnDDz/UrFmzNHXqVL3wwgu2Mfr166f7779fCQkJ6t+/v4YMGaLDhw8rOTlZLVu21BtvvHGJ9woAAMA9uUWA3LRpkxITE6u0bd68ucrp6MoAWZc5c+YoPDxcixcv1oIFC+Tn56c777xT06dP19VXX+3wdQMAADRGHlartcLZiwAaUnFxse01lb6+vs5eDgxQO/dF7dwb9UN9Gt01kAAAAGhYBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIy4TYDcunWrYmNjFRISouDgYA0aNEjJyclGYxw6dEhTp07VLbfcouDgYHXt2lW33367Pv/8c5WVlTXQygEAABoXb2cv4EJkZmZq1KhR8vX1VUxMjPz9/bV69WqNGzdOeXl5mjhxYr1j7Nu3T1FRUTpx4oSioqJ0++23q6ioSOvWrdOECROUmZmp+fPnX4K9AQAAcG8eVqu1wtmLqMu5c+d088036+DBg0pNTVWPHj0kSQUFBYqKitKBAwf0ww8/KCQkpM5xnnnmGS1cuFDx8fF6/PHHbe1Wq1WRkZHKy8vT9u3b6x0H7qe4uFi5ubnq0KGDfH19nb0cGKB27ovauTfqh/q4/CnszMxM7d27V6NHj7aFR0kKDAzUlClTVFJSosTExHrH2bdvnyRpyJAhVdqDgoLUu3dvSdKJEycct3AAAIBGyuUDZFZWliRp4MCB1fqioqIkSRs3bqx3nO7du0uSvv766yrtVqtVmzdvlsViUbdu3exdLgAAQKPn8tdA7tmzR5LUuXPnan0Wi0X+/v7Kycmpd5xJkyYpJSVFL774otLT03XttdfaroFs0aKFlixZohYtWtQ7TnFxsflOwKlKSkqq/Ar3Qe3cF7Vzb9TPPV3Kyw1cPkAWFhZKkgICAmrsv/zyy23b1KVNmzZKTU3Vo48+qtTUVKWlpUmSWrRooXHjxum66667oPUcPHiQO7bdVH5+vrOXgItE7dwXtXNv1M99eHl5KTQ09JLN5/IB0lFycnI0ZswY+fn5af369frDH/6ggoICffHFF3r11VeVkZGh9evXy8vLq85xgoODL9GK4SglJSXKz8+XxWKRj4+Ps5cDA9TOfVE790b9UB+XD5CVRx5rO8pYVFSkoKCgesd54oknlJubqx9//FEWi0WS5O/vr6efflpHjhzR+++/ry+//FL/+Z//Wec43I3mvnx8fKifm6J27ovauTfqh9q4/E00ldc+Vl4Leb78/HydOnWq3kO2RUVF2rx5s8LCwmzh8Xx9+/aVJG3fvt0BKwYAAGjcXD5A9unTR5KUkZFRrS89Pb3KNrUpLS2VJB0/frzG/mPHjkmSmjdvftHrBAAAaCpcPkD2799fnTp10sqVK6scISwoKNDs2bPl4+OjMWPG2NoPHz6sXbt2qaCgwNZ2xRVXqGvXrsrLy1NCQkKV8a1Wq+bNmyfp30ciAQAAUDuXD5De3t6aO3euysvLFR0drcmTJ2vatGmKjIzU7t27NX36dHXs2NG2fVxcnHr16qW1a9dWGee1116Tt7e3Jk2apOHDh2v69OmaOHGievbsqV27dmnYsGEaMGDAJd47AAAA9+PyN9FIUr9+/ZSSkqL4+HglJyertLRU4eHhiouLU0xMzAWNMXjwYH399deaO3euNm/erI0bN8rX11dhYWF6/vnnNX78+AbeCwAAgMbB5d+FDdiLd7q6L2rnvqide6N+qI/Ln8IGAACAayFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABgxG0C5NatWxUbG6uQkBAFBwdr0KBBSk5ONh7n6NGjeuGFF3TjjTfKYrHo6quv1uDBg7Vw4cIGWDUAAEDj4+3sBVyIzMxMjRo1Sr6+voqJiZG/v79Wr16tcePGKS8vTxMnTrygcbZv366YmBhZrVYNGTJEw4cP16lTp7Rr1y6lpKRo/PjxDbwnAAAA7s/lA+S5c+c0efJkeXp6at26derRo4ck6fnnn1dUVJRmzJih4cOHKyQkpM5xCgsLdc8990iSvvnmG1133XXV5gEAAED9XP4UdmZmpvbu3avRo0fbwqMkBQYGasqUKSopKVFiYmK94yxcuFB5eXl6+eWXq4VHSfL2dvksDQAA4BJcPjVlZWVJkgYOHFitLyoqSpK0cePGesdJSkqSh4eHhg0bpuzsbGVkZKi4uFhdu3bVoEGD5OPjc0HrKS4uNlg9XEFJSUmVX+E+qJ37onbujfq5J19f30s2l8sHyD179kiSOnfuXK3PYrHI399fOTk5dY5RUlKiHTt2qHXr1vrwww8VHx+v8vJyW3+nTp20dOlSXXvttfWu5+DBgyorKzPcC7iC/Px8Zy8BF4nauS9q596on/vw8vJSaGjoJZvP5QNkYWGhJCkgIKDG/ssvv9y2TW1OnjypsrIynThxQm+88Ybi4uI0ZswYlZaWatGiRfrLX/6iMWPGaMuWLfWm9+Dg4IvbEThNSUmJ8vPzZbFYLvhIM1wDtXNf1M69UT/Ux+UDpCNUHm0sKyvTI488UuWu7WnTpmn37t1KTk7WqlWrdNddd9U51qU8PAzH8vHxoX5uitq5L2rn3qgfauPyN9FUHnms7ShjUVFRrUcnfz+GJN1xxx3V+ivbtm3bdrHLBAAAaDJcPkBWXvtYeS3k+fLz83Xq1Kl6z/n7+fnZTj0HBgZW669s4wYZAACA+rl8gOzTp48kKSMjo1pfenp6lW3q0rdvX0nSP//5z2p9lW31PUsSAAAAbhAg+/fvr06dOmnlypXavn27rb2goECzZ8+Wj4+PxowZY2s/fPiwdu3apYKCgirjPPTQQ5KkOXPmyGq12trz8/O1YMECeXp6atiwYQ27MwAAAI2AywdIb29vzZ07V+Xl5YqOjtbkyZM1bdo0RUZGavfu3Zo+fbo6duxo2z4uLk69evXS2rVrq4xzyy236Mknn9TOnTsVGRmpZ599VpMnT1ZkZKQOHjyol156SV26dLnUuwcAAOB23OIu7H79+iklJUXx8fFKTk5WaWmpwsPDFRcXp5iYmAseZ+bMmQoPD9fHH3+sZcuWycPDQz169NDs2bM1dOjQBtwDAACAxsPDarVWOHsRQEMqLi5Wbm6uOnTowOMo3Ay1c1/Uzr1RP9TH5U9hAwAAwLUQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIw0eIC0Wq3asWOHzp4929BTAQAA4BKwO0D+4x//0MyZM5WRkVGl/cyZMxo/frxCQ0MVGRmpa665RqtWrbJ3OgAAADiZ3QFyyZIleuutt1RRUfWV2q+99pqSkpJUUVGhiooKWa1WPfLII9qxY4e9UwIAAMCJ7A6Qf//73+Xr66vbbrvN1lZSUqLFixerWbNm+uKLL7Rv3z499thjKi0t1YIFC+ydEgAAAE5kd4A8cuSI2rVrJ0/Pfw/1/fffq6ioSHfccYcGDx6swMBAvfzyy/Lz89PGjRvtnRIAAABOZHeAtFqtatmyZZW277//Xh4eHoqKirK1tWjRQp06ddLBgwftnRIAAABOZHeAbNGihY4dO1albdOmTZKkW265pUq7j49PlSOVAAAAcD92p7mwsDAdOHBAO3fulCQdP35c3333nVq1aqVu3bpV2fbQoUNq3bq1vVMCAADAiewOkCNGjFBFRYViY2M1bdo0DR06VCUlJYqJiamyXW5urg4fPqzQ0FB7pwQAAIAT2R0gH330UUVEROjXX3/V/PnztXPnTnXp0kVTp06tsl1ycrIkqW/fvvZOCQAAACfytncAHx8frVmzRuvXr1d2drY6dOig6Oho+fr6VtnOy8tLEyZM0PDhw+2dEgAAAE5kd4CUJE9PT0VHR9e5zZNPPumIqQAAAOBk3BINAAAAI3YHyGPHjunbb7/V7t27q/UtWrRIffr0UWhoqGJjY5WdnW3vdAAAAHAyuwPkggULNHLkSG3ZsqVK+6effqpnnnlGO3bs0MmTJ5WWlqahQ4fqxIkT9k4JAAAAJ7I7QH733Xfy8vLS0KFDq7TPnj1bkjRx4kQtWbJEvXv31pEjRzR//nx7pwQAAIAT2R0gc3NzZbFY5O/vb2v76aeflJubq1tuuUWvvPKKoqOjtWjRInl5eelvf/ubvVMCAADAiewOkCdOnFDbtm2rtG3evFmS9Kc//cnWZrFYFBoaqn379tk7JQAAAJzI7gDp6empU6dOVWn7/vvv5eHhoVtvvbVKe0BAgEpKSuydEgAAAE5kd4AMCQlRTk6OTp48KUkqLS1VRkaGWrRooRtuuKHKtsePH1erVq3snRIAAABOZHeAHDhwoEpLSzV+/HitX79eEydO1IkTJxQVFSVv738/p7ygoED79u3TVVddZe+UAAAAcCK730Tz1FNPKSkpSRs2bNA333yjiooK+fr6VnsXdkpKiioqKtS7d297pwQAAIAT2R0g27Rpo4yMDM2dO1e7d+9Whw4dNGHCBHXr1q3Kdps2bdJ1112nP/7xj/ZOCQAAACdyyLuwg4OD9frrr9e5zZw5cxwxFQAAAJyMd2EDAADAiEOOQFY6cuSINmzYoOzsbBUVFenyyy9XWFiYbrvtNl155ZWOnAoAAABO4pAAefbsWU2fPl2LFy9WaWlptf5mzZpp3LhxiouLU/PmzR0xJQAAAJzE7gBZXl6uu+++23YH9pVXXqmuXbuqbdu2Onz4sLKzs3X06FF9+OGH2r17t1asWCEPDw9HrB0AAABOYHeAXLJkiTZs2KCAgAC9+uqruvvuu6s8/7GsrEyJiYmaPn26MjIytHTpUt133332TgsAAAAnsfsmmuXLl8vDw0MJCQkaO3ZslfAoSV5eXrrvvvv06aefqqKiQomJifZOCQAAACeyO0D+/PPP6tixo/r371/ndv3791enTp30888/2zslAAAAnMjuAHnmzBm1bNnygrZt2bKliouL7Z0SAAAATmR3gLRYLMrOztaZM2fq3O5f//qXsrOz1aZNG3unBAAAgBPZHSD79u2r06dP68UXX6xzuxdffFGnT59Wv3797J0SAAAATmT3XdiTJ0/WypUrtXjxYm3ZskUTJkxQeHi42rRpoyNHjmjHjh16//33tXPnTvn4+GjSpEmOWDcAAACcxO4AGRYWpgULFuiJJ57Qzz//XGNArKiokK+vr95//32FhYXZOyUAAACcyCHvwh45cqQyMzN17733qk2bNqqoqLD9tGnTRmPHjlVmZqZGjBjhiOkAAADgRA57F3bXrl01b948SVJhYaFOnTolf39/BQQE2Lbp37+/CgoK9OOPPzpqWgAAAFxiDguQ5wsICKgSHCvl5eXp5MmTDTElAAAALhGHnMIGAABA00GABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYMX6Mz6xZsy56sjNnzlz0ZwEAAOAajAPk66+/Lg8Pj4uarKKi4qI/CwAAANdgHCAjIiIIgQAAAE2YcYBct25dQ6wDAAAAboKbaAAAAGCEAAkAAAAjBEgAAAAYIUACAADAiNsEyK1btyo2NlYhISEKDg7WoEGDlJycfNHjWa1Wde/eXUFBQRo1apQDVwoAANC4Gd+F7QyZmZkaNWqUfH19FRMTI39/f61evVrjxo1TXl6eJk6caDzmc889p8LCwgZYLQAAQOPm8kcgz507p8mTJ8vT01Pr1q3TO++8o5kzZyorK0tdunTRjBkzdODAAaMxV61apRUrVui///u/G2bRAAAAjZjLB8jMzEzt3btXo0ePVo8ePWztgYGBmjJlikpKSpSYmHjB4x07dkzPPPOM7rrrLg0ZMqQhlgwAANCouXyAzMrKkiQNHDiwWl9UVJQkaePGjRc83tNPPy0vLy+73ukNAADQlLn8NZB79uyRJHXu3Llan8Vikb+/v3Jyci5orOXLl2vNmjVaunSpgoKCVFBQYLye4uJi48/AuUpKSqr8CvdB7dwXtXNv1M89+fr6XrK5XD5AVt7oEhAQUGP/5ZdffkE3wxw6dEhTp07V6NGjFR0dfdHrOXjwoMrKyi7683Ce/Px8Zy8BF4nauS9q596on/vw8vJSaGjoJZvP5QOko0yaNEnNmjWz+9R1cHCwg1aES6WkpET5+fmyWCzy8fFx9nJggNq5L2rn3qgf6uPyAbLyyGNtRxmLiooUFBRU5xjLli1TamqqFi9erFatWtm1nkt5eBiO5ePjQ/3cFLVzX9TOvVE/1Mblb6KpvPax8lrI8+Xn5+vUqVP1HrLdvn27JOmBBx5QUFCQ7ef666+XJKWnpysoKEiRkZEOXj0AAEDj4/JHIPv06aPZs2crIyOj2htj0tPTbdvUpVevXjp9+nS19tOnTyspKUlXXXWVBg4cqPbt2ztu4QAAAI2Uh9VqrXD2Iupy7tw59ezZU4cOHVJqaqrtWZAFBQWKiorSgQMHtGXLFnXs2FGSdPjwYRUWFspisSgwMLDOsffv36/rr79eUVFR+vLLLxt8X+AcxcXFys3NVYcOHTgV42aonfuidu6N+qE+Ln8K29vbW3PnzlV5ebmio6M1efJkTZs2TZGRkdq9e7emT59uC4+SFBcXp169emnt2rVOXDUAAEDj5fKnsCWpX79+SklJUXx8vJKTk1VaWqrw8HDFxcUpJibG2csDAABoUlz+FDZgL07FuC9q576onXujfqiPy5/CBgAAgGshQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYMRtAuTWrVsVGxurkJAQBQcHa9CgQUpOTr6gz1ZUVCg1NVVTpkxRRESEQkJC1K5dO/Xp00dvvfWWiouLG3j1AAAAjYe3sxdwITIzMzVq1Cj5+voqJiZG/v7+Wr16tcaNG6e8vDxNnDixzs+fPXtWsbGxat68uSIjIxUVFaXi4mJlZGRoxowZWrdundauXavLLrvsEu0RAACA+3L5AHnu3DlNnjxZnp6eWrdunXr06CFJev755xUVFaUZM2Zo+PDhCgkJqXUMLy8vvfTSS3r44YcVFBRkay8tLdXYsWOVkpKijz/+WJMmTWro3QEAAHB7Ln8KOzMzU3v37tXo0aNt4VGSAgMDNWXKFJWUlCgxMbHOMZo1a6Znn322SnisbJ8yZYokaePGjQ5fOwAAQGPk8gEyKytLkjRw4MBqfVFRUZLsC3/NmjWT9NtRSgAAANTP5U9h79mzR5LUuXPnan0Wi0X+/v7Kycm56PGXLFkiqeaAWhNuuHE/JSUlVX6F+6B27ovauTfq5558fX0v2VwuHyALCwslSQEBATX2X3755bZtTKWmpmrRokXq1q2bxo4de0GfOXjwoMrKyi5qPjhXfn6+s5eAi0Tt3Be1c2/Uz314eXkpNDT0ks3n8gGyoWzdulUPPfSQAgIC9Omnn6p58+YX9Lng4OAGXhkcraSkRPn5+bJYLPLx8XH2cmCA2rkvaufeqB/q4/IBsvLIY21HGYuKiqrdHFOfbdu2aeTIkfLw8FBSUpK6d+9+wZ+9lIeH4Vg+Pj7Uz01RO/dF7dwb9UNtXP4mmsprHyuvhTxffn6+Tp06ZXTIdtu2bRoxYoQqKiqUlJSkG2+80WFrBQAAaApcPkD26dNHkpSRkVGtLz09vco29akMj+Xl5Vq5cqV69uzpuIUCAAA0ES4fIPv3769OnTpp5cqV2r59u629oKBAs2fPlo+Pj8aMGWNrP3z4sHbt2qWCgoIq4/z4448aMWKEysrKtGLFCvXq1euS7QMAAEBj4vLXQHp7e2vu3LkaNWqUoqOjq7zKMDc3VzNmzFDHjh1t28fFxSkxMVHvvfee7r33XknSyZMnNWLECBUUFGjQoEHasGGDNmzYUGWewMBAPfHEE5d03wAAANyRywdISerXr59SUlIUHx+v5ORklZaWKjw8XHFxcYqJian384WFhbJarZKktLQ0paWlVdumQ4cOBEgAAIAL4GG1WiucvQigIRUXFys3N1cdOnTgbkI3Q+3cF7Vzb9QP9XH5ayABAADgWgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYIUACAADACAESAAAARgiQAAAAMEKABAAAgBECJAAAAIwQIAEAAGCEAAkAAAAjBEgAAAAYcZsAuXXrVsXGxiokJETBwcEaNGiQkpOTjcY4e/asZs2apRtvvFEWi0XXXHONJk+erKNHjzbQqgEAABofb2cv4EJkZmZq1KhR8vX1VUxMjPz9/bV69WqNGzdOeXl5mjhxYr1jlJeX65577lF6erpuvvlmDRs2THv27FFCQoK+/fZbpaWlqXXr1pdgbwAAANybywfIc+fOafLkyfL09NS6devUo0cPSdLzzz+vqKgozZgxQ8OHD1dISEid4yxbtkzp6ekaPXq0PvroI3l4eEiSPvnkE02ZMkWvvvqq5syZ09C7AwAA4PZc/hR2Zmam9u7dq9GjR9vCoyQFBgZqypQpKikpUWJiYr3jJCQkSJL+/Oc/28KjJI0bN06dOnXSihUrdObMGcfvAFyCl5eXs5eAi0Tt3Be1c2/UD3Vx+QCZlZUlSRo4cGC1vqioKEnSxo0b6xyjuLhYP/zwg7p27VrtSKWHh4duu+02nT59Wtu2bXPQquFKfH19FRoaKl9fX2cvBYaonfuidu6N+qE+Lh8g9+zZI0nq3LlztT6LxSJ/f3/l5OTUOcbevXtVXl6u0NDQGvsr2yvnAgAAQO1cPkAWFhZKkgICAmrsv/zyy23b1DdGYGBgjf2VY9c3DgAAANwgQAIAAMC1uHyArO/oYFFRUa1HJ38/RkFBQY399R3lBAAAwL+5fICsvPaxpusT8/PzderUqVqvbazUqVMneXp61nqtZGV7TddZAgAAoCqXD5B9+vSRJGVkZFTrS09Pr7JNbVq0aKGbbrpJ2dnZOnDgQJW+iooKbdiwQX5+frrhhhsctGoAAIDGy+UDZP/+/dWpUyetXLlS27dvt7UXFBRo9uzZ8vHx0ZgxY2zthw8f1q5du6qdrn7ggQckSa+88ooqKips7YsWLdK+ffsUGxurFi1aNPDeAAAAuD+XD5De3t6aO3euysvLFR0drcmTJ2vatGmKjIzU7t27NX36dHXs2NG2fVxcnHr16qW1a9dWGeeee+5RVFSUVq5cqSFDhmjChAkKCwvTlClT5OHhoW3btvFubTdhz3vRKyoqlJqaqilTpigiIkIhISFq166d+vTpo7feekvFxcUNvHo44r3257NarerevbuCgoI0atQoB64Uv+eo2h09elQvvPCC7c/Oq6++WoMHD9bChQsbYNWo5Ij6HTp0SFOnTtUtt9yi4OBgde3aVbfffrs+//xzlZWVNdDKm7bly5frqaee0oABA9SmTRsFBQVp6dKlxuOUl5frgw8+UEREhNq2bavOnTtr/Pjx2rdv30Wty+VfZShJ/fr1U0pKiuLj45WcnKzS0lKFh4crLi5OMTExFzSGp6enli1bprfffluffvqptmzZIg8PD3Xt2lWRkZFKS0vj3dpuwN73op89e1axsbFq3ry5IiMjFRUVpeLiYmVkZGjGjBlat26d1q5dq8suu+wS7VHT4oj32v/ec889xyO4LgFH1W779u2KiYmR1WrVkCFDNHz4cJ06dUq7du1SSkqKxo8f38B70jQ5on779u1TVFSUTpw4oaioKN1+++0qKirSunXrNGHCBGVmZmr+/PmXYG+alldffVW5ublq1aqVLBaLcnNzL2qcp556SgkJCerevbsee+wxHTp0SF999ZUyMjKUlpZmfB+Ih9Vqrah/s8bj3Llzuvnmm3Xw4EGlpqbaXo9YUFCgqKgoHThwQD/88EO979ZesmSJ/uu//qvWd2s/+OCDvFvbwRxRu9LSUr3zzjt6+OGHFRQUVKV97NixSklJ0SuvvKJJkyY19O40OY767p1v1apVeuCBB/Tmm2/queeeU1RUlL788suG2oUmy1G1KywsVEREhIqLi/XVV1/puuuuqzaPt7dbHNdwK46q3zPPPKOFCxcqPj5ejz/+uK3darUqMjJSeXl52r59u9F3GPX75ptvFBoaqpCQEL399tuKi4vTe++9p3vvvfeCx8jMzNSwYcMUERGhr776Sj4+PpKk1NRUxcbGauDAgUpKSjJal8ufwnY03q3tvhxRu2bNmunZZ5+tEh4r26dMmSKp/ldj4uI46rtX6dixY3rmmWd01113aciQIQ2xZPx/jqrdwoULlZeXp5dffrlaeJREeGwgjqpf5anO33/fgoKC1Lt3b0nSiRMnHLdwSJIGDBhgdyivzCzTpk2zhUdJGjx4sCIjI5WRkWF8ZLPJBUjere2+HFG7ujRr1kyS5OXlddFjoHaOrt/TTz8tLy8vzZo1yzELRK0cVbukpCR5eHho2LBhys7O1gcffKB33nlHf/3rX1VSUuLYRcPGUfXr3r27JOnrr7+u0m61WrV582ZZLBZ169bN3uWiAWRlZcnPz0+33nprtb6L/f9nk/vr3qV+t3ZERISdK0YlR9SuLkuWLJFU8x+ysJ8j67d8+XKtWbNGS5cuVVBQUK0vCYBjOKJ2JSUl2rFjh1q3bq0PP/xQ8fHxKi8vt/V36tRJS5cu1bXXXuvYxcNh371JkyYpJSVFL774otLT03XttdfaroFs0aKFlixZwtNMXNDp06d1+PBhhYeH13iA5PzMYqLJHYHk3druyxG1q01qaqoWLVqkbt26aezYsRe9RtTOUfWrvAt09OjRio6OdugaUTNH1O7kyZMqKyvTiRMn9MYbbyguLk7Z2dnasWOHnnvuOe3fv19jxozhSQgNwFHfvTZt2ig1NVWDBg1SWlqa3nnnHX3yyScqLCzUmDFjarwsAc5XX/0vNrM0uQAJ/N7WrVv10EMPKSAgQJ9++qmaN2/u7CWhDpMmTVKzZs04de1mKo82lpWVafz48Zo4caKuvPJKBQcHa9q0aRoxYoRyc3O1atUqJ68UtcnJydEf//hHHTt2TOvXr1deXp5+/vlnPf/883rzzTc1fPhwHuXThDS5AMm7td2XI2r3e9u2bdPIkSPl4eGhpKQk2zU+cDxH1G/ZsmVKTU3VX/7yF7Vq1crha0TNHPnnpiTdcccd1for27h23PEc9WfnE088odzcXH3++efq3bu3/P39ddVVV+npp5/Wo48+qu+//56nILig+up/sZmlyQVI3q3tvhxRu/Nt27ZNI0aMUEVFhZKSknTjjTc6bK2ozhH1q3wb1QMPPKCgoCDbz/XXXy/pt9ebBgUFKTIy0sGrb9ocUTs/Pz8FBwdLqvnyn8o2TmE7niPqV1RUpM2bNyssLEwWi6Vaf9++fSWpyhvj4Br8/PzUtm1b7d+/v8YjxBebWZpcgOTd2u7LEbWrVBkey8vLtXLlSvXs2dNxC0WNHFG/Xr16aezYsdV+Kl8ocNVVV2ns2LEaOnSog1fftDnqu1cZMv75z39W66ts4xmCjueI+pWWlkqSjh8/XmP/sWPHJIlLgFxUnz59dPr0aW3evLlaX+V/A6Y3/Ta5AMm7td2Xo2r3448/asSIESorK9OKFSvUq1evS7YPTZkj6hcTE6N333232s/LL78sSbrmmmv07rvvaurUqZdux5oAR333HnroIUnSnDlzZLVabe35+flasGCBPD09NWzYsIbdmSbIEfW74oor1LVrV+Xl5dmeKVjJarVq3rx5kv79lwQ4x/Hjx7Vr165qQb8ys8ycObPKI7NSU1OVlZWlgQMHGv/lrcm9iUaq/ZVOubm5mjFjRpVXOj3++ONKTEys9tT38vJyxcbG2l5l2KdPH+Xk5GjNmjUKCQlReno6rzJsAPbW7uTJk7rhhhtktVo1aNAg3XTTTdXmCAwM1BNPPHHJ9qkpccR3ryb79+/X9ddfz5toGpCjajdt2jS99957at++vW6//XaVlpbqr3/9q44ePao///nPtgf6w7EcUb/U1FTdfffdOnfunPr3768ePXrIarVq/fr1OnbsmIYNG1YtXMJ+CQkJ2rRpkyRpx44d+sc//qFbb71VV199tSSpd+/euv/++yVJ8fHxmjVrlqZOnaoXXnihyjiTJk2yvcpwyJAhOnz4sJKTk+Xn56fU1FR16dLFaF1N7jmQkuPfrb18+XLNnz9fLVu21NixY/XSSy8RHhuIvbUrLCy0HflIS0tTWlpatW06dOhAgGwgjvjuwTkcVbuZM2cqPDxcH3/8sZYtWyYPDw/16NFDs2fP5tKDBuSI+g0ePFhff/215s6dq82bN2vjxo3y9fVVWFiYnn/+ed5j3kA2bdpU7U1BmzdvrnI6ujJA1mXOnDkKDw/X4sWLtWDBAvn5+enOO+/U9OnTbWHURJM8AgkAAICL1+SugQQAAIB9CJAAAAAwQoAEAACAEQIkAAAAjBAgAQAAYIQACQAAACMESAAAABghQAIAAMAIARIAAABGCJAA4MKWLl2qoKAgRUdHO3spAGBDgATgFqKjoxUUFKT4+Hhbm9VqVXx8fJU2d7J27VrFx8fru+++c/ZSAMCIt7MXAAAXq6CgQLNmzZIkvfDCC05ejbl169YpMTFRktS3b98atwkICFDXrl3Vvn37S7k0AKgTARIAXNjQoUM1dOhQZy8DAKrgFDYAAACMECABuKXHH39c119/ve2fg4KCqvwsXbq0yvZlZWVasmSJhg0bptDQUF155ZXq3r27HnnkEf3000+1zlF53WVBQYFefvll9ezZU23bttUf/vAH23a7d+/W22+/rTvvvFPXXXedLBaLQkJCNGTIEC1YsEAlJSVVxt2/f7+CgoJsp69nzZpVZe3nj13fTTSnT5/W22+/rQEDBqhDhw5q166dbr75Zr344os6fPhwvft15swZvfbaa+rZs6csFos6d+6scePGac+ePTV+9uzZs5o3b56ioqIUEhKi1q1bq0uXLoqIiNCzzz6rH3/8scbPAWhcOIUNwC116dJFN9xwg7Zt2yZJuvXWW6v0t2nTxvZ7q9Wqu+++W5s2bZIktWvXTu3bt9fevXu1YsUKffXVV1qwYIFGjRpV41wnTpzQbbfdpr179yosLEzdunVTcXGxrf+VV17R6tWr5e/vrzZt2ujaa6/V0aNH9f333+v777/XmjVrlJycLB8fH0mSr6+vbr31Vu3Zs0dHjx5V+/btq1zjaLFYLujfwaFDhzRy5Ej98ssv8vDwUFhYmJo3b66dO3dq/vz5+vzzz/XFF1+oZ8+eNX6+qKhIgwcP1s8//6ywsDCFhoYqOztbycnJ+vbbb/XNN98oJCTEtn1ZWZliYmK0ceNGSVJISIi6dOmikydPKicnRzt27FBQUJD+4z/+44LWD8B9ESABuKVnnnlGo0ePth2FTElJqXXbRx55RJs2bVLv3r311ltvKTw8XJJUXl6uBQsW6KWXXtKTTz6p66+/Xl26dKn2+U8++UTdu3fXDz/8oM6dO0uSzpw5Y+u/6667NHnyZN14443y8PCwte/atUtPPvmkNm7cqPfee09PP/20pN8CYkpKih5//HElJibq3nvvvaibgB555BH98ssv6ty5sz777DPbfh05ckQPP/ywMjMzdf/992vTpk0KDAys9vmPPvpI4eHh+t///V+FhoZKkvbt26fY2FhlZ2frtdde04IFC2zbr1+/Xhs3blRwcLC++OILXXfddba+c+fOacOGDVX2H0DjxSlsAI3aN998o9TUVLVv316JiYm2kCVJnp6eeuKJJ/Twww+ruLhY77//fo1jeHl5aenSpbbwKEktWrSw/T46Olo33XRTtfAUFhamDz74QJJsp6sd5e9//7uysrIk/TsIVmrTpo0SEhIUEBCggwcPKiEhocYxPD099emnn9rCoyR16tRJ06dPl1Q9lGdnZ0uShg8fXiU8SpK3t7cGDx6sQYMG2b9zAFweRyABNGpJSUmSpNGjRysoKKjGbYYNG6YPP/xQ3377bY39/fv3V8eOHeuc5+jRo/ryyy+1detWHTlyRGfPnlVFRYWtPzs7W2fOnKkSPO3x9ddfS5J69+6tG2+8sVp/UFCQ7rvvPs2fP19ff/21Jk6cWG2bgQMH6uqrr67W3qtXL0m/nfo/efKkWrZsKUnq0KGDpN9C+bFjx9S6dWuH7AsA90OABNCo/d///Z8kac2aNdq8eXON21Rez/jrr7/W2H/NNdfUOceqVav05JNP6tSpU7VuU1FRoZMnTzosQFYeDezevXut21Qelazc9vdqOl0vVb1+tKioyBYgo6Oj1bVrV+3cuVPXXnut+vbtq969e6tXr17q1auXmjdvflH7AsD9ECABNGpWq1WStGfPnlrvLK50/nWN57vssstq/cz+/fv16KOP6uzZsxo5cqQee+wxhYWFKSAgQN7e3iovL9cVV1whSSotLb24nahBZVg9P+z9Xtu2bats+3u17Zen57+vbjr/KGqLFi20fv16zZo1S0lJSUpLS1NaWpqk3x54fv/99+vFF1+s898XgMaBAAmgUfPz85MkzZs3T/fdd5/Dx09KStLZs2d10003aeHChVXCl/TbHdwNwd/fX9JvN8zUpvIxPpXbOkLr1q315ptv6o033tAvv/yi//mf/1F6errWr1+vefPm6ddff9WiRYscNh8A18RNNADc1oXc8Vt5Gvfnn39ukDXs379f0m+PEfp9eJSkLVu21PpZe+5YDgsLkyTt3Lmz1m127NhRZVtH8vDwUPfu3fXggw/qs88+sz13Mzk5ucFCMwDXQYAE4LbOP1X6r3/9q8ZtRo4cKUn6/PPP6zxad7Eqr2nMz8+v1ldRUaF333231s9Wrr+2U+d1GTJkiCRp06ZN2rp1a7V+q9WqJUuWVNm2Id1yyy223x88eLDB5wPgXARIAG6rVatWCggIkPTbncE1uf322zVw4ECdPHlSQ4cOtT1M/Hz79u3TO++8U+vjburSp08fSdJXX32lv/3tb7b2oqIiTZw4scZwV6nyDuhNmzZVe1tNfXr37q3IyEhJvz0P8vwjkUePHtW4ceNUWFio4OBgjR071mjs2sybN0/vvPOODhw4UKX9X//6l15//XVJv10Lef7jjgA0TlwDCcBteXh46K677tJHH32k++67T9dcc43tjuGnn37a9kzCTz75RA8++KC++eYb3XHHHbryyivVoUMHlZWV6ddff9WxY8ckSVOnTjVew5/+9CdFRkYqKytLd911lzp27KiWLVtq165dKi4u1vz58zVhwoQaPzt8+HDNnDlTW7ZsUXh4uDp37ixvb29ZLBZ98skn9c790Ucf2d5EExERoW7dusnHx0c7d+5UaWmpWrZsqYSEhBofIn4x8vLytGDBAr388stq27at2rVrp5KSEu3bt0+nT5+Wt7e35syZ47A7zQG4LgIkALc2Y8YMBQYGavXq1crJybE9kueee+6xbRMUFKSkpCStWbNGy5cv19atW/XTTz/J29tbbdu21YABA3THHXdo8ODBxvN7enpqxYoVeuONN5SUlKSDBw/q9OnT6tu3ryZOnKjIyMhaA2T79u2VlJSkt956S1u3btWWLVtUXl5ue95ifdq1a6f09HR98MEHWrVqlfbs2aNz586pY8eOGjx4sCZNmqR27doZ71Ntxo8fr9atW+u7775TTk6OfvnlF5WXlys4OFgRERF6/PHHqz1gHEDj5GG1Wivq3wwAAAD4DddAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACMECABAABghAAJAAAAIwRIAAAAGCFAAgAAwAgBEgAAAEYIkAAAADBCgAQAAIARAiQAAACM/D+3XyhwZUlCJQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = 10\n",
    "outputs = []\n",
    "losses = []\n",
    "list1 = list(range(epochs))\n",
    "\n",
    "for epoch in tqdm.tqdm(list1):\n",
    "   i = 0\n",
    "   for emb in loader:\n",
    "        i+=1\n",
    "        reconstructed = model(emb[0])\n",
    "        loss = loss_function(reconstructed, emb[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "        if i%100==0:\n",
    "            print(loss)\n",
    "\n",
    "        #outputs.append((epochs, emb, reconstructed))\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses[-100:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalscm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
