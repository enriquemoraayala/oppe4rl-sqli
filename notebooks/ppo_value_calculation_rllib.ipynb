{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"../src/\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import ray.rllib.agents.ppo as ppo\n",
        "from ray import tune\n",
        "from ray.rllib.agents.ppo import PPOTrainer\n",
        "import ray\n",
        "from ray.tune.registry import register_env\n",
        "from ray.tune.logger import pretty_print\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from ray.rllib.algorithms import Algorithm\n",
        "from ray.rllib.models.preprocessors import get_preprocessor"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  import imp\n/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1678807712660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gym_waf.envs.waf_brain_env import WafBrainEnv"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807718660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../src/outputs_ppo/run_history_rllib.csv', sep=';', index_col=0)\n",
        "s2 = '../src/outputs_ppo/emb_states_rllib.npy'\n",
        "np_emb_state_ = np.load(s2, allow_pickle=True)\n",
        "print(np_emb_state_.shape[0])\n",
        "print(df.shape[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "109\n109\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807720736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   episode  step                 original_payload  \\\n0        0     0  ;waitfor delay '0:0:__TIME__'--   \n1        0     1  ;waitfor delay '0:0:__TIME__'--   \n2        0     2  ;waitfor delay '0:0:__TIME__'--   \n3        0     3  ;waitfor delay '0:0:__TIME__'--   \n4        0     4  ;waitfor delay '0:0:__TIME__'--   \n\n                                               state  action  \\\n0                    ;waitfor delay '0:0:__TIME__'--      25   \n1                    ;waitfor delay '0:0:__TIME__'--      19   \n2                    ;waitfor delay '0:0:__TIME__'--      14   \n3  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      15   \n4  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      11   \n\n                                          next_state    reward  win  \n0                    ;waitfor delay '0:0:__TIME__'-- -0.516129    0  \n1                    ;waitfor delay '0:0:__TIME__'-- -0.516129    0  \n2  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0  \n3  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0  \n4  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>episode</th>\n      <th>step</th>\n      <th>original_payload</th>\n      <th>state</th>\n      <th>action</th>\n      <th>next_state</th>\n      <th>reward</th>\n      <th>win</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>25</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>-0.516129</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>19</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>-0.516129</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>14</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>15</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>11</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807722188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to estimate the discounted reward from the current state, action until the end of the episode\n",
        "episodes = list(df.episode.unique())\n",
        "print(len(episodes))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "20\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807725830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(episodes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807727077
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating expected reward for episode\n",
        "\n",
        "discount = 0.99 #based in the PPO original paper, default discount\n",
        "num_eps = 0\n",
        "for ep in episodes:\n",
        "    print(ep)\n",
        "    df_ = df[df['episode'] == ep].copy()\n",
        "    df_.sort_values(by=['step'], ascending=False, inplace=True)\n",
        "    cum_reward = 0.0\n",
        "    j = 0\n",
        "    for i,step in df_.iterrows():\n",
        "        if j == 0:\n",
        "            cum_reward = step.reward\n",
        "        else:\n",
        "            cum_reward = cum_reward + discount * step.reward\n",
        "        df.at[i,'exp_reward'] = cum_reward\n",
        "        j += 1"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807729430
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "   episode  step                 original_payload  \\\n0        0     0  ;waitfor delay '0:0:__TIME__'--   \n1        0     1  ;waitfor delay '0:0:__TIME__'--   \n2        0     2  ;waitfor delay '0:0:__TIME__'--   \n3        0     3  ;waitfor delay '0:0:__TIME__'--   \n4        0     4  ;waitfor delay '0:0:__TIME__'--   \n\n                                               state  action  \\\n0                    ;waitfor delay '0:0:__TIME__'--      25   \n1                    ;waitfor delay '0:0:__TIME__'--      19   \n2                    ;waitfor delay '0:0:__TIME__'--      14   \n3  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      15   \n4  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      11   \n\n                                          next_state    reward  win  \\\n0                    ;waitfor delay '0:0:__TIME__'-- -0.516129    0   \n1                    ;waitfor delay '0:0:__TIME__'-- -0.516129    0   \n2  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n3  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n4  ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n\n   exp_reward  \n0   -3.605828  \n1   -3.094860  \n2   -2.583892  \n3   -2.436445  \n4   -2.288998  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>episode</th>\n      <th>step</th>\n      <th>original_payload</th>\n      <th>state</th>\n      <th>action</th>\n      <th>next_state</th>\n      <th>reward</th>\n      <th>win</th>\n      <th>exp_reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>25</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>-0.516129</td>\n      <td>0</td>\n      <td>-3.605828</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>19</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>-0.516129</td>\n      <td>0</td>\n      <td>-3.094860</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>14</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.583892</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>15</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.436445</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>11</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.288998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807733725
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['episode'] == 0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "    episode  step                 original_payload  \\\n0         0     0  ;waitfor delay '0:0:__TIME__'--   \n1         0     1  ;waitfor delay '0:0:__TIME__'--   \n2         0     2  ;waitfor delay '0:0:__TIME__'--   \n3         0     3  ;waitfor delay '0:0:__TIME__'--   \n4         0     4  ;waitfor delay '0:0:__TIME__'--   \n5         0     5  ;waitfor delay '0:0:__TIME__'--   \n6         0     6  ;waitfor delay '0:0:__TIME__'--   \n7         0     7  ;waitfor delay '0:0:__TIME__'--   \n8         0     8  ;waitfor delay '0:0:__TIME__'--   \n9         0     9  ;waitfor delay '0:0:__TIME__'--   \n10        0    10  ;waitfor delay '0:0:__TIME__'--   \n11        0    11  ;waitfor delay '0:0:__TIME__'--   \n12        0    12  ;waitfor delay '0:0:__TIME__'--   \n13        0    13  ;waitfor delay '0:0:__TIME__'--   \n14        0    14  ;waitfor delay '0:0:__TIME__'--   \n15        0    15  ;waitfor delay '0:0:__TIME__'--   \n16        0    16  ;waitfor delay '0:0:__TIME__'--   \n17        0    17  ;waitfor delay '0:0:__TIME__'--   \n18        0    18  ;waitfor delay '0:0:__TIME__'--   \n19        0    19  ;waitfor delay '0:0:__TIME__'--   \n20        0    20  ;waitfor delay '0:0:__TIME__'--   \n21        0    21  ;waitfor delay '0:0:__TIME__'--   \n\n                                                state  action  \\\n0                     ;waitfor delay '0:0:__TIME__'--      25   \n1                     ;waitfor delay '0:0:__TIME__'--      19   \n2                     ;waitfor delay '0:0:__TIME__'--      14   \n3   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      15   \n4   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      11   \n5   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      22   \n6   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--       3   \n7   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      14   \n8   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--      12   \n9   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--       6   \n10  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...      19   \n11  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...       3   \n12  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...      21   \n13  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...       1   \n14  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...      11   \n15  ;waitf\n ||\n #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TI...      11   \n16  ;waitf\n\n ||\n\n #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__...      18   \n17  ;waitf\n\n ||\n\n #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__...      13   \n18  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...      20   \n19  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...       6   \n20  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...      21   \n21  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...      10   \n\n                                           next_state    reward  win  \\\n0                     ;waitfor delay '0:0:__TIME__'-- -0.516129    0   \n1                     ;waitfor delay '0:0:__TIME__'-- -0.516129    0   \n2   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n3   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n4   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n5   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n6   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n7   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n8   ;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'-- -0.148936    0   \n9   ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME... -0.142857    0   \n10  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME... -0.142857    0   \n11  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME... -0.142857    0   \n12  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME... -0.142857    0   \n13  ;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME... -0.142857    0   \n14  ;waitf\n ||\n #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TI... -0.117647    0   \n15  ;waitf\n\n ||\n\n #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__... -0.113208    0   \n16  ;waitf\n\n ||\n\n #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__... -0.113208    0   \n17  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:... -0.127273    0   \n18  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:... -0.127273    0   \n19  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:... -0.127273    0   \n20  ;waitf\n\n  ||\n\n  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:... -0.127273    0   \n21  ;waitf\n\n\\n \\n ||\n\n\\n \\n #~fx8;?B\\ndelay#~fx8;?...  0.000000    1   \n\n    exp_reward  \n0    -3.605828  \n1    -3.094860  \n2    -2.583892  \n3    -2.436445  \n4    -2.288998  \n5    -2.141552  \n6    -1.994105  \n7    -1.846658  \n8    -1.699211  \n9    -1.551764  \n10   -1.410336  \n11   -1.268907  \n12   -1.127479  \n13   -0.986050  \n14   -0.844622  \n15   -0.728151  \n16   -0.616075  \n17   -0.504000  \n18   -0.378000  \n19   -0.252000  \n20   -0.126000  \n21    0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>episode</th>\n      <th>step</th>\n      <th>original_payload</th>\n      <th>state</th>\n      <th>action</th>\n      <th>next_state</th>\n      <th>reward</th>\n      <th>win</th>\n      <th>exp_reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>25</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>-0.516129</td>\n      <td>0</td>\n      <td>-3.605828</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>19</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>-0.516129</td>\n      <td>0</td>\n      <td>-3.094860</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>14</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.583892</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>15</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.436445</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>11</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.288998</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>5</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>22</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-2.141552</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>6</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>3</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-1.994105</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>7</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>14</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-1.846658</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>8</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>12</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>-0.148936</td>\n      <td>0</td>\n      <td>-1.699211</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>9</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitfor#~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME__'--</td>\n      <td>6</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>-0.142857</td>\n      <td>0</td>\n      <td>-1.551764</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>10</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>19</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>-0.142857</td>\n      <td>0</td>\n      <td>-1.410336</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>11</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>3</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>-0.142857</td>\n      <td>0</td>\n      <td>-1.268907</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>12</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>21</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>-0.142857</td>\n      <td>0</td>\n      <td>-1.127479</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>13</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>1</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>-0.142857</td>\n      <td>0</td>\n      <td>-0.986050</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>14</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf || #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TIME...</td>\n      <td>11</td>\n      <td>;waitf\f ||\f #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TI...</td>\n      <td>-0.117647</td>\n      <td>0</td>\n      <td>-0.844622</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>15</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f ||\f #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__TI...</td>\n      <td>11</td>\n      <td>;waitf\f\f ||\f\f #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__...</td>\n      <td>-0.113208</td>\n      <td>0</td>\n      <td>-0.728151</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>16</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f\f ||\f\f #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__...</td>\n      <td>18</td>\n      <td>;waitf\f\f ||\f\f #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__...</td>\n      <td>-0.113208</td>\n      <td>0</td>\n      <td>-0.616075</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>17</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f\f ||\f\f #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:__...</td>\n      <td>13</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>-0.127273</td>\n      <td>0</td>\n      <td>-0.504000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>18</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>20</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>-0.127273</td>\n      <td>0</td>\n      <td>-0.378000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>19</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>6</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>-0.127273</td>\n      <td>0</td>\n      <td>-0.252000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>20</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>21</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>-0.127273</td>\n      <td>0</td>\n      <td>-0.126000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>21</td>\n      <td>;waitfor delay '0:0:__TIME__'--</td>\n      <td>;waitf\f\f  ||\f\f  #~fx8;?B\\ndelay#~fx8;?B\\n'0:0:...</td>\n      <td>10</td>\n      <td>;waitf\f\f\\n \\n ||\f\f\\n \\n #~fx8;?B\\ndelay#~fx8;?...</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807747722
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we have to access to the ppo policy in order to compute the prob(action|state)\n",
        "# load ppo policy from checkpoint\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "ray.init(local_mode='local-model')\n",
        "algo = Algorithm.from_checkpoint(\"../src/ckpt_ppo_agent_tf2/checkpoint_000006\")\n",
        "ppo_policy = algo.get_policy()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:105: DeprecationWarning: DeprecationWarning: local mode is an experimental feature that is no longer maintained and will be removed in the future.For debugging consider using Ray debugger. \n  return func(*args, **kwargs)\n2023-03-14 15:29:15,275\tINFO worker.py:1538 -- Started a local Ray instance.\n2023-03-14 15:29:16,229\tINFO algorithm_config.py:2492 -- Executing eagerly (framework='tf2'), with eager_tracing=tf2. For production workloads, make sure to set eager_tracing=True  in order to match the speed of tf-static-graph (framework='tf'). For debugging purposes, `eager_tracing=False` is the best choice.\n2023-03-14 15:29:16,245\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n2023-03-14 15:29:16,304\tWARNING worker.py:837 -- `ray.get_gpu_ids()` will always return the empty list when called from the driver. This is because Ray does not manage GPU allocations to the driver process.\n:actor_name:RolloutWorker\n[2023-03-14 15:29:16,341 E 8675 8675] core_worker.cc:1450: Pushed Error with JobID: 01000000 of type: task with message: \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 676, in make\n    return registry.make(id, **kwargs)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 490, in make\n    versions = self.env_specs.versions(namespace, name)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 220, in versions\n    self._assert_name_exists(namespace, name)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 297, in _assert_name_exists\n    raise error.NameNotFound(message)\ngym.error.NameNotFound: Environment `rl-waf` doesn't exist.\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 585, in __init__\n    self.env = env_creator(copy.deepcopy(self.env_context))\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/env/utils.py\", line 52, in _gym_env_creator\n    raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\nray.rllib.utils.error.EnvError: The env string you provided ('rl-waf') is:\na) Not a supported/installed environment.\nb) Not a tune-registered environment creator.\nc) Not a valid env class string.\n\nTry one of the following:\na) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n   For VizDoom support: Install VizDoom\n   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n   `pip install vizdoomgym`.\n   For PyBullet support: `pip install pybullet`.\nb) To register your custom env, do `from ray import tune;\n   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n   Then in your config, do `config['env'] = [name]`.\nc) Make sure you provide a fully qualified classpath, e.g.:\n   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv` at time: 1.67881e+09\n2023-03-14 15:29:16,341\tERROR actor.py:968 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 676, in make\n    return registry.make(id, **kwargs)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 490, in make\n    versions = self.env_specs.versions(namespace, name)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 220, in versions\n    self._assert_name_exists(namespace, name)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/gym/envs/registration.py\", line 297, in _assert_name_exists\n    raise error.NameNotFound(message)\ngym.error.NameNotFound: Environment `rl-waf` doesn't exist.\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 585, in __init__\n    self.env = env_creator(copy.deepcopy(self.env_context))\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/env/utils.py\", line 52, in _gym_env_creator\n    raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\nray.rllib.utils.error.EnvError: The env string you provided ('rl-waf') is:\na) Not a supported/installed environment.\nb) Not a tune-registered environment creator.\nc) Not a valid env class string.\n\nTry one of the following:\na) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n   For VizDoom support: Install VizDoom\n   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n   `pip install vizdoomgym`.\n   For PyBullet support: `pip install pybullet`.\nb) To register your custom env, do `from ray import tune;\n   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n   Then in your config, do `config['env'] = [name]`.\nc) Make sure you provide a fully qualified classpath, e.g.:\n   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n[2023-03-14 15:29:16,351 E 8675 8675] core_worker.cc:1450: Pushed Error with JobID: 01000000 of type: task with message: \u001b[36mray::RolloutWorker.apply::Exiting()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n    raise e\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n    return func(self, *args, **kwargs)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py\", line 607, in <lambda>\n    lambda w: w.assert_healthy()\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 857, in assert_healthy\n    is_healthy = self.policy_map and self.input_reader and self.output_writer\nAttributeError: 'RolloutWorker' object has no attribute 'policy_map' at time: 1.67881e+09\n2023-03-14 15:29:16,352\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. \u001b[36mray::RolloutWorker.apply::Exiting()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n    raise e\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n    return func(self, *args, **kwargs)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py\", line 607, in <lambda>\n    lambda w: w.assert_healthy()\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 857, in assert_healthy\n    is_healthy = self.policy_map and self.input_reader and self.output_writer\nAttributeError: 'RolloutWorker' object has no attribute 'policy_map'\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ":actor_name:RolloutWorker\n"
        },
        {
          "output_type": "error",
          "ename": "RayTaskError(AttributeError)",
          "evalue": "\u001b[36mray::RolloutWorker.apply::Exiting()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n    raise e\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n    return func(self, *args, **kwargs)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py\", line 607, in <lambda>\n    lambda w: w.assert_healthy()\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 857, in assert_healthy\n    is_healthy = self.policy_map and self.input_reader and self.output_writer\nAttributeError: 'RolloutWorker' object has no attribute 'policy_map'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRayTaskError(AttributeError)\u001b[0m              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39menable_eager_execution()\n\u001b[1;32m      4\u001b[0m ray\u001b[38;5;241m.\u001b[39minit(local_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal-model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[43mAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../src/ckpt_ppo_agent_tf2/checkpoint_000006\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ppo_policy \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mget_policy()\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:278\u001b[0m, in \u001b[0;36mAlgorithm.from_checkpoint\u001b[0;34m(checkpoint, policy_ids, policy_mapping_fn, policies_to_train)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`checkpoint_info[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_version\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]` in `Algorithm.from_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()` must be 1.0 or later! You are using a checkpoint with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_version\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    271\u001b[0m state \u001b[38;5;241m=\u001b[39m Algorithm\u001b[38;5;241m.\u001b[39m_checkpoint_info_to_algorithm_state(\n\u001b[1;32m    272\u001b[0m     checkpoint_info\u001b[38;5;241m=\u001b[39mcheckpoint_info,\n\u001b[1;32m    273\u001b[0m     policy_ids\u001b[38;5;241m=\u001b[39mpolicy_ids,\n\u001b[1;32m    274\u001b[0m     policy_mapping_fn\u001b[38;5;241m=\u001b[39mpolicy_mapping_fn,\n\u001b[1;32m    275\u001b[0m     policies_to_train\u001b[38;5;241m=\u001b[39mpolicies_to_train,\n\u001b[1;32m    276\u001b[0m )\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:306\u001b[0m, in \u001b[0;36mAlgorithm.from_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo `config` found in given Algorithm state!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 306\u001b[0m new_algo \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Set the new algo's state.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m new_algo\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:441\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m     }\n\u001b[1;32m    439\u001b[0m }\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/tune/trainable/trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_ip \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:566\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;66;03m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;66;03m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;66;03m#   in each training iteration.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;66;03m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;66;03m# has been deprecated.\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mWorkerSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_execution_plan_api\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:169\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _setup:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# constructor).\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# errors.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:239\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[0;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds_shards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_workers_after_construction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    248\u001b[0m     local_worker\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39mnum_actors() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcreate_env_on_local_worker\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39maction_space)\n\u001b[1;32m    252\u001b[0m ):\n",
            "File \u001b[0;32m/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:612\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39mforeach_actor(\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m w: w\u001b[38;5;241m.\u001b[39massert_healthy()\n\u001b[1;32m    608\u001b[0m ):\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# Simiply raise the error, which will get handled by the try-except\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# clause around the _setup().\u001b[39;00m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m--> 612\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget()\n",
            "\u001b[0;31mRayTaskError(AttributeError)\u001b[0m: \u001b[36mray::RolloutWorker.apply::Exiting()\u001b[39m (pid=8675, ip=10.0.0.5, repr=<ray.rllib.evaluation.rollout_worker._modify_class.<locals>.Class object at 0x7f5fe87bea30>)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n    raise e\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n    return func(self, *args, **kwargs)\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py\", line 607, in <lambda>\n    lambda w: w.assert_healthy()\n  File \"/anaconda/envs/oppe4rl_22/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 857, in assert_healthy\n    is_healthy = self.policy_map and self.input_reader and self.output_writer\nAttributeError: 'RolloutWorker' object has no attribute 'policy_map'"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678807758212
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "oppe4rl_22",
      "language": "python",
      "display_name": "oppe4rl_22"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "oppe4rl_22"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}